import json
import os
from typing import Dict, Any, List
from dataclasses import dataclass
from pathlib import Path
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from dotenv import load_dotenv
import logging
import time  # æ·»åŠ åœ¨æ–‡ä»¶å¼€å¤´çš„importéƒ¨åˆ†

#import ssl
#ssl._create_default_https_context = ssl._create_unverified_context
# åŠ è½½ç¯å¢ƒå˜é‡å¹¶è®¾ç½®æ—¥å¿—
load_dotenv()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class TestCase:
    name: str
    input_data: Dict[str, Any]
    expected_output: Dict[str, Any]

@dataclass
class TestResult:
    test_case: TestCase
    actual_output: Dict[str, Any]
    passed: bool
    error_message: str = ""
    execution_time: float = 0.0  # æ·»åŠ æ‰§è¡Œæ—¶é—´å­—æ®µ

class PromptTestRunner:
    def __init__(self):
        load_dotenv()
#        model_name = os.getenv("OPENAI_MODEL_NAME", "gpt-3.5-turbo")
        
        # å®šä¹‰æç¤ºè¯ç›®å½•
        self.prompt_dir = "prompt_engineering/bot194/01"  # æ”¹ä¸ºæ­£ç¡®çš„ç›®å½•è·¯å¾„
        
        # å®šä¹‰æç¤ºè¯é…ç½®æ˜ å°„
        self.prompt_configs = {
            "å»ºé€ ç³»ç»Ÿ": {
                "prompt": "bot_skill_build_prompt_02.md",
                "test_cases": "bot_skill_build_test_cases.md"
            },
            "èµ„æºç®¡ç†": {
                "prompt": "resource_manager_prompt_02.md",
                "test_cases": "resource_manager_test_cases.md"
            },
            "æ•°ç»„å®šä¹‰": {
                "prompt": "array_definition_prompt.md",
                "test_cases": "array_definition_test_cases.md"
            },

        }
        
        # é€‰æ‹©æç¤ºè¯é…ç½®
        self.select_prompt_config()
        
        # æ ¹æ®ä¸åŒæ¨¡å‹é…ç½®åˆé€‚çš„å‚æ•°
#        temperature = float(os.getenv("TEMPERATURE", "0.7"))
        
#        self.chat = ChatOpenAI(
#            model=model_name,
#            temperature=temperature,
#            base_url=os.getenv("OPENAI_API_BASE"),
#            api_key=os.getenv("OPENAI_API_KEY"),
#            streaming=True
#        )
        

        # ä»æ–‡ä»¶åŠ è½½ç³»ç»Ÿæç¤ºè¯
        prompt_file = Path(__file__).parent.parent / self.prompt_dir / self.prompt_filename
        print(f"Loading prompt from: {prompt_file}")
        with open(prompt_file, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # å¤„ç†æç¤ºè¯ä¸­çš„å˜é‡æ ‡è®°
        content = content.replace("{", "{{").replace("}", "}}")  # è½¬ä¹‰æ‰€æœ‰çš„èŠ±æ‹¬å·
        content = content.replace("{{{{", "{").replace("}}}}", "}")  # æ¢å¤åŸæœ‰çš„åŒèŠ±æ‹¬å·

#å½“å‰è¾“å…¥: {{input}}
#å½“å‰ä¸Šä¸‹æ–‡: {{context}}

        # ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿(æ³¨å…¥æ¨¡æ¿æ ‡è®°)
        self.system_prompt = content + f"""

æ³¨æ„ï¼š
1. ä½ å¿…é¡»ç›´æ¥è¿”å›JSONæ ¼å¼æ•°æ®ï¼Œä¸è¦åœ¨JSONå‰åæ·»åŠ ä»»ä½•å…¶ä»–æ–‡æœ¬ã€å¯¹è¯æˆ–è¯´æ˜
2. è¿”å›çš„JSONå¿…é¡»æ˜¯ä¸€ä¸ªå®Œæ•´ä¸”æœ‰æ•ˆçš„JSONå¯¹è±¡
3. æ‰€æœ‰å­—æ®µå€¼å¿…é¡»ç¬¦åˆå…¶é¢„æœŸçš„æ•°æ®ç±»å‹ï¼ˆä¾‹å¦‚ï¼šæ•°å­—ã€å­—ç¬¦ä¸²ã€å¸ƒå°”å€¼ã€å¯¹è±¡ç­‰ï¼‰
4. ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„å­—æ®µéƒ½å­˜åœ¨äºè¾“å‡ºä¸­
5. ä¸è¦åœ¨JSONä¸­æ·»åŠ æ³¨é‡Š
6. è¾“å‡ºJSONçš„é”®å€¼ç»Ÿä¸€ä½¿ç”¨å°å†™å­—æ¯
"""

        self.prompt = ChatPromptTemplate.from_messages([
            ("system", self.system_prompt)
        ])
#        self.prompt = ChatPromptTemplate.from_messages([
#            SystemMessage(content=self.system_prompt)
#        ])

#        print(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
        print("æç¤ºè¯åŠ è½½å®Œæˆï¼Œé•¿åº¦ï¼š", len(self.system_prompt))

    def select_prompt_config(self):
        """é€‰æ‹©è¦æµ‹è¯•çš„æç¤ºè¯é…ç½®"""
        print("\nğŸ“‹ å¯ç”¨çš„æç¤ºè¯ç³»ç»Ÿï¼š")
        for i, name in enumerate(self.prompt_configs.keys(), 1):
            print(f"{i}. {name}")
        
        while True:
            try:
                choice = input("\nè¯·é€‰æ‹©è¦æµ‹è¯•çš„æç¤ºè¯ç³»ç»Ÿ (1-{}): ".format(len(self.prompt_configs)))
                choice = int(choice)
                if 1 <= choice <= len(self.prompt_configs):
                    selected_name = list(self.prompt_configs.keys())[choice - 1]
                    config = self.prompt_configs[selected_name]
                    self.prompt_filename = config["prompt"]
                    self.test_cases_filename = config["test_cases"]
                    print(f"\nâœ… å·²é€‰æ‹©: {selected_name}")
                    print(f"æç¤ºè¯æ–‡ä»¶: {self.prompt_filename}")
                    print(f"æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶: {self.test_cases_filename}")
                    break
                print(f"âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·è¾“å…¥1-{len(self.prompt_configs)}ä¹‹é—´çš„æ•°å­—")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")

    def load_test_cases(self, test_file_path: str) -> List[TestCase]:
        """ä»Markdownæ–‡ä»¶åŠ è½½æµ‹è¯•ç”¨ä¾‹"""
        test_cases = []
        
        with open(test_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        def extract_json_content(text: str, marker: str) -> str:
            """ä»æ–‡æœ¬ä¸­æå–JSONå†…å®¹"""
            start_marker = f"##### {marker}\n```json"
            end_marker = "```"
            start = text.find(start_marker)
            if start == -1:
                return ""
            start = start + len(start_marker)
            end = text.find(end_marker, start)
            if end == -1:
                return ""
            json_text = text[start:end].strip()
            return json_text
        
        # åˆ†å‰²æµ‹è¯•ç”¨ä¾‹éƒ¨åˆ†
        test_sections = content.split('#### æµ‹è¯•ç”¨ä¾‹')
        
        for section in test_sections[1:]:  # è·³è¿‡ç¬¬ä¸€ä¸ªåˆ†å‰²ï¼ˆæ–‡ä»¶å¤´éƒ¨ï¼‰
            try:
                # æå–æµ‹è¯•ç”¨ä¾‹åç§°
                name = section.split('\n')[0].strip()
                
                # æå–input.jsonå’Œoutput.jsonå†…å®¹
                input_text = extract_json_content(section, "input.json")
                output_text = extract_json_content(section, "output.json")
                
                if not input_text or not output_text:
                    print(f"âš ï¸ è­¦å‘Š: æµ‹è¯•ç”¨ä¾‹ {name} ç¼ºå°‘è¾“å…¥æˆ–è¾“å‡ºJSON")
                    continue
                
                # è§£æJSON
                try:
                    input_json = json.loads(input_text)
                    output_json = json.loads(output_text)
                    
                    test_cases.append(TestCase(
                        name=name,
                        input_data=input_json,
                        expected_output=output_json
                    ))
                    print(f"âœ… æˆåŠŸåŠ è½½æµ‹è¯•ç”¨ä¾‹: {name}")
                except json.JSONDecodeError as je:
                    print(f"âŒ JSONè§£æé”™è¯¯ - æµ‹è¯•ç”¨ä¾‹ {name}:")
                    print(f"  Input JSON:\n{input_text[:200]}")
                    print(f"  Output JSON:\n{output_text[:200]}")
                    print(f"  é”™è¯¯ä¿¡æ¯: {str(je)}")
                    continue
                    
            except Exception as e:
                print(f"âŒ è§£æé”™è¯¯ - æµ‹è¯•ç”¨ä¾‹ {name if 'name' in locals() else 'unknown'}:")
                print(f"  é”™è¯¯ä¿¡æ¯: {str(e)}")
                continue
        
        if not test_cases:
            print("âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æµ‹è¯•ç”¨ä¾‹")
        else:
            print(f"\nğŸ“ æ€»å…±åŠ è½½äº† {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            
        return test_cases

    def run_test(self, test_case: Dict[str, Any], expected_output: Dict[str, Any]) -> tuple[bool, float]:
        """è¿è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹å¹¶è¿”å›ç»“æœå’Œæ‰§è¡Œæ—¶é—´"""
        start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
        try:
            # å‡†å¤‡è¾“å…¥
            input_json = json.dumps(test_case, ensure_ascii=False, indent=2)
            
            # æ„å»ºæ¶ˆæ¯æ ¼å¼
            system_content = self.system_prompt.format(
                input=test_case.get("input", ""),
                context=json.dumps(test_case.get("context", {}), ensure_ascii=False)
            )
            
            # è°ƒç”¨API
            try:
                #result = self.chat.invoke(
                #    [{"role": "system", "content": system_content}]
                #)
                # ä½¿ç”¨å°†contextå’Œinput ç›´æ¥å˜æˆ HumanMessage
                messages = []
                messages.append(SystemMessage(content=system_content))
                messages.append(HumanMessage(content=input_json))

                #messages.append(SystemMessage(content="you are a helpful assistant."))
                #messages.append(HumanMessage(content="my name is bob."))
                #print(messages)

                result = self.chat.invoke(messages)


                # è§£æè¾“å‡º
                try:
                    # æ¸…ç†å“åº”å†…å®¹ï¼Œåˆ é™¤ JSON å‰åçš„æ‰€æœ‰å†…å®¹
                    content = result.content
                    json_start = content.find('{')
                    json_end = content.rfind('}')
                    if json_start != -1 and json_end != -1:
                        content = content[json_start:json_end + 1]
                    
                    output = json.loads(content)
                    # éªŒè¯è¾“å‡ºæ ¼å¼
                    self._validate_output_format(output)
                    # æ¯”è¾ƒè¾“å‡º
                    if self._compare_outputs(output, expected_output):
                        print(f"âœ… æµ‹è¯•é€šè¿‡ (è€—æ—¶: {time.time() - start_time:.2f}ç§’)")
                        return True, time.time() - start_time
                    else:
                        print(f"\nâŒ æµ‹è¯•å¤±è´¥ (è€—æ—¶: {time.time() - start_time:.2f}ç§’)")
                        print("\næµ‹è¯•ç”¨ä¾‹:")
                        print("è¾“å…¥:")
                        print(json.dumps(test_case, ensure_ascii=False, indent=2))
                        print("\næœŸæœ›è¾“å‡º:")
                        print(json.dumps(expected_output, ensure_ascii=False, indent=2))
                        print("\nå®é™…è¾“å‡º:")
                        print(json.dumps(output, ensure_ascii=False, indent=2))
                        return False, time.time() - start_time
                except json.JSONDecodeError:
                    print(f"\nâŒ AIå“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼:")
                    print(result.content)
                    print("\næµ‹è¯•ç”¨ä¾‹:")
                    print("è¾“å…¥:")
                    print(json.dumps(test_case, ensure_ascii=False, indent=2))
                    print("\næœŸæœ›è¾“å‡º:")
                    print(json.dumps(expected_output, ensure_ascii=False, indent=2))
                    return False, time.time() - start_time
                    
            except Exception as e:
                print(f"\nâŒ APIè°ƒç”¨é”™è¯¯: {str(e)}")
                logger.error(f"APIè°ƒç”¨é”™è¯¯: {str(e)}")
                return False, time.time() - start_time
                
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•æ‰§è¡Œå‡ºé”™: {str(e)} (è€—æ—¶: {time.time() - start_time:.2f}ç§’)")
            print("\næµ‹è¯•ç”¨ä¾‹:")
            print("è¾“å…¥:")
            print(json.dumps(test_case, ensure_ascii=False, indent=2))
            print("\næœŸæœ›è¾“å‡º:")
            print(json.dumps(expected_output, ensure_ascii=False, indent=2))
            return False, time.time() - start_time

    def _compare_outputs(self, actual: Dict[str, Any], expected: Dict[str, Any]) -> bool:
        """æ¯”è¾ƒå®é™…è¾“å‡ºå’Œé¢„æœŸè¾“å‡ºåªæ£€æŸ¥æµ‹è¯•ç”¨ä¾‹ä¸­å­˜åœ¨çš„é”®å€¼"""
        def compare_dicts(actual_dict: Dict[str, Any], expected_dict: Dict[str, Any], path: str = "") -> bool:
            for key, expected_value in expected_dict.items():
                if key not in actual_dict:
                    print(f"âŒ ç¼ºå°‘å­—æ®µ {path}{key}")
                    return False
                    
                actual_value = actual_dict[key]
                
                if isinstance(expected_value, dict):
                    if not isinstance(actual_value, dict):
                        print(f"å­—æ®µç±»å‹ä¸åŒ¹é… {path}{key}")
                        return False
                    if not compare_dicts(actual_value, expected_value, f"{path}{key}."):
                        return False
                elif isinstance(expected_value, (int, float)):
                    if not isinstance(actual_value, (int, float)):
                        print(f"âŒ æ•°å€¼ç±»å‹ä¸åŒ¹é… {path}{key}")
                        return False
                    if abs(actual_value - expected_value) > 0.01:  # å…è®¸å°æ•°ç‚¹è¯¯å·®
                        print(f"âŒ æ•°å€¼ä¸åŒ¹é… {path}{key}:")
                        print(f"   æœŸæœ›: {expected_value}")
                        print(f"   å®é™…: {actual_value}")
                        return False
                elif isinstance(expected_value, bool):
                    if not isinstance(actual_value, bool):
                        print(f"âŒ å¸ƒå°”ç±»å‹ä¸åŒ¹é… {path}{key}")
                        return False
                    if actual_value != expected_value:
                        print(f"âŒ å¸ƒå°”å€¼ä¸åŒ¹é… {path}{key}:")
                        print(f"   æœŸæœ›: {expected_value}")
                        print(f"   å®é™…: {actual_value}")
                        return False
                    
            return True
            
        # æ£€æŸ¥æµ‹è¯•ç”¨ä¾‹ä¸­å­˜åœ¨çš„å­—æ®µ
        return compare_dicts(actual, expected)

    def _validate_output_format(self, output: Dict[str, Any]):
        """éªŒè¯è¾“å‡ºæ ¼å¼æ˜¯å¦ç¬¦åˆè§„èŒƒ"""
        # åŸºæœ¬å­—æ®µæ£€æŸ¥
        if not isinstance(output, dict):
            raise ValueError("Output must be a dictionary")
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µæ˜¯å¦å­˜åœ¨
        required_fields = ["updated_context", "process", "botstatus", "message", "dialogue"]
        for field in required_fields:
            if field not in output:
                raise ValueError(f"Missing required field: {field}")

    def run_model_tests(self, model_name: str, test_cases: List[TestCase]) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªæ¨¡å‹çš„æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹å¹¶è¿”å›ç»“æœ"""
        # è®¾ç½®æ¨¡å‹
        os.environ["OPENAI_MODEL_NAME"] = model_name
        print(f"\nğŸ”„ å¼€å§‹æµ‹è¯•æ¨¡å‹: {model_name}")
        
        # é‡æ–°åˆå§‹åŒ– chat å®ä¾‹
        if "claude" in model_name.lower():
            headers = {
                "Content-Type": "application/json",
                "anthropic-version": "2023-06-01"
            }
            max_tokens = 4096
        else:
            headers = None
            max_tokens = None
        
        try:
            self.chat = ChatOpenAI(
                model=model_name,
                temperature=float(os.getenv("TEMPERATURE", "0.7")),
                base_url=os.getenv("OPENAI_API_BASE"),
                api_key=os.getenv("OPENAI_API_KEY"),
                streaming=True
            )
            #ä½¿ç”¨claudeæ¨¡å‹ï¼Œå¿…é¡»å¼ºåˆ¶å¼€å¯ streaming=True    
            #    default_headers=headers,
            #    max_tokens=max_tokens
            #)
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æ¨¡å‹å¤±è´¥: {str(e)}")
            raise
        
        results = []
        total_time = 0
        test_times = []
        
        for test_case in test_cases:
            print(f"\nğŸ”„ è¿è¡Œæµ‹è¯•ç”¨ä¾‹: {test_case.name}")
            result, execution_time = self.run_test(test_case.input_data, test_case.expected_output)
            results.append(result)
            test_times.append(execution_time)
            total_time += execution_time
            
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        total = len(results)
        passed = sum(1 for r in results if r)
        pass_rate = (passed/total)*100 if total > 0 else 0
        avg_time = total_time / total if total > 0 else 0
        
        return {
            "model": model_name,
            "total": total,
            "passed": passed,
            "failed": total - passed,
            "pass_rate": pass_rate,
            "total_time": total_time,
            "avg_time": avg_time,
            "test_times": test_times  # ä¿å­˜æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹çš„æ‰§è¡Œæ—¶é—´
        }

def main():
    # åˆå§‹åŒ–æµ‹è¯•è¿è¡Œå™¨
    runner = PromptTestRunner()
    
    # åŠ è½½æµ‹è¯•ç”¨ä¾‹
    test_file = Path(__file__).parent.parent / runner.prompt_dir / runner.test_cases_filename
    test_cases = runner.load_test_cases(str(test_file))
    
    # å¦‚æœæ²¡æœ‰æµ‹è¯•ç”¨ä¾‹ï¼Œç›´æ¥è¿”å›
    if not test_cases:
        print("\nâŒ æ²¡æœ‰å¯æ‰§è¡Œçš„æµ‹è¯•ç”¨ä¾‹ï¼Œç¨‹åºé€€å‡º")
        return
    
    # å•é€‰æ¨¡å‹åˆ—è¡¨
    selectable_models = [
        "moonshot-v1-32k",
        "Doubao-pro-128k",
        "gpt-3.5-turbo",
        "claude-3-sonnet-20240229",
        "claude-3-5-sonnet-20240620",
        "claude-3-5-sonnet-20241022",
        "c-3-5-sonnet-20241022",
        "gpt-4-turbo",
        "qwen-max",
        "glm-4"
    ]
    
    # å®Œæ•´æµ‹è¯•æ¨¡å‹åˆ—è¡¨ï¼ˆå½“é€‰æ‹©"æµ‹è¯•æ‰€æœ‰æ¨¡å‹"æ—¶ä½¿ç”¨ï¼‰
    all_test_models = [
        "moonshot-v1-32k",
        "Doubao-pro-128k",
        "claude-3-5-sonnet-20241022",
        "gpt-4-turbo",
        "glm-4"
    ]
    
    # æ˜¾ç¤ºæ¨¡å‹åˆ—è¡¨
    print("\nğŸ“‹ å¯ç”¨çš„æ¨¡å‹ï¼š")
    for i, model in enumerate(selectable_models, 1):
        print(f"{i}. {model}")
    print("0. æµ‹è¯•baselineæ¨¡å‹")
    
    # è·å–ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹
    while True:
        try:
            model_choice = input("\nè¯·é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹ç¼–å· (0-{}): ".format(len(selectable_models)))
            model_choice = int(model_choice)
            if 0 <= model_choice <= len(selectable_models):
                break
            print(f"âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·è¾“å…¥0-{len(selectable_models)}ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    # æ˜¾ç¤ºæµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
    print("\nğŸ“‹ å¯ç”¨çš„æµ‹è¯•ç”¨ä¾‹ï¼š")
    for i, test_case in enumerate(test_cases, 1):
        print(f"{i}. {test_case.name}")
    print("0. è¿è¡Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹")
    
    # è·å–ç”¨æˆ·é€‰æ‹©
    while True:
        try:
            choice = input("\nè¯·é€‰æ‹©è¦è¿è¡Œçš„æµ‹è¯•ç”¨ä¾‹ç¼–å· (0-{}): ".format(len(test_cases)))
            choice = int(choice)
            if 0 <= choice <= len(test_cases):
                break
            print(f"âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·è¾“å…¥0-{len(test_cases)}ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    # å‡†å¤‡è¦è¿è¡Œçš„æµ‹è¯•ç”¨ä¾‹
    selected_test_cases = test_cases if choice == 0 else [test_cases[choice - 1]]
    
    # å‡†å¤‡è¦æµ‹è¯•çš„æ¨¡å‹
    selected_models = all_test_models if model_choice == 0 else [selectable_models[model_choice - 1]]
    
    # è¿è¡Œæµ‹è¯•å¹¶é›†ç»“æœ
    model_results = []
    for model in selected_models:
        result = runner.run_model_tests(model, selected_test_cases)
        model_results.append(result)
    
    # è¾“å‡ºæ¯”è¾ƒç»“æœ
    print("\nğŸ“Š æ¨¡å‹æµ‹è¯•ç»“æœæ¯”è¾ƒ:")
    
    # å®šä¹‰è¡¨æ ¼æ ¼å¼
    FORMAT = "{:<35} {:>8} {:>8} {:>8} {:>10} {:>12} {:>12}"
    
    # æ‰“å°è¡¨å¤´å’Œåˆ†éš”çº¿
    header_line = "=" * 95
    print(header_line)
    print(FORMAT.format(
        "æ¨¡å‹åç§°", "æ€»æ•°", "é€šè¿‡", "å¤±è´¥", "é€šè¿‡ç‡", "æ€»è€—æ—¶", "å¹³å‡è€—æ—¶"
    ))
    print("-" * 95)
    
    # æ‰“å°æ•°æ®è¡Œ
    for result in model_results:
        print(FORMAT.format(
            result['model'],
            str(result['total']),
            str(result['passed']),
            str(result['failed']),
            f"{result['pass_rate']:.1f}%",
            f"{result['total_time']:.2f}s",
            f"{result['avg_time']:.2f}s"
        ))
    
    print(header_line)
    
    # å¦‚æœåªè¿è¡Œäº†ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œæ˜¾ç¤ºè¯¦ç»†çš„æ—¶é—´ä¿¡æ¯
    if len(selected_test_cases) > 1:
        print("\nğŸ“Š å„æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œæ—¶é—´:")
        for i, test_case in enumerate(selected_test_cases):
            for result in model_results:
                print(f"{result['model']} - {test_case.name}: {result['test_times'][i]:.2f}ç§’")

if __name__ == "__main__":
    main()
