import streamlit as st
import json
import os
from typing import Dict, Any, List
from dataclasses import dataclass
from pathlib import Path
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_ollama import ChatOllama
#from langchain_community.llms import Ollama
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from dotenv import load_dotenv
import logging
import time
import datetime
import csv
import pandas as pd
from typing import Optional, Tuple

# åŠ è½½ç¯å¢ƒå˜é‡å¹¶è®¾ç½®æ—¥å¿—
load_dotenv()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class TestCase:
    name: str
    input_data: Dict[str, Any]
    expected_output: Dict[str, Any]

@dataclass
class TestResult:
    test_case: TestCase
    actual_output: Dict[str, Any]
    passed: bool
    error_message: str = ""
    execution_time: float = 0.0

@dataclass
class ModelVendorConfig:
    name: str                    # æ¨¡å‹å•†åç§°
    models: List[str]           # è¯¥å•†å®¶æä¾›çš„æ¨¡å‹åˆ—è¡¨
    baseline_models: List[str]  # è¯¥å•†å®¶çš„åŸºçº¿æ¨¡å‹åˆ—è¡¨
    api_key_env: str           # ç¯å¢ƒå˜é‡ä¸­API KEYçš„åç§°
    base_url: str              # APIåŸºç¡€URL
    model_class: Optional[str] = None  # æ¨¡å‹åŸºç±»åç§°ï¼Œå¯é€‰

# æ¨¡å‹å•†é…ç½®
MODEL_VENDORS = {
    "SMALLAI": ModelVendorConfig(
        name="SmallAI",
        models=["moonshot-v1-32k",
        "Doubao-pro-128k",
        "gemini-2.0-flash-exp",
        "gpt-3.5-turbo",
        "claude-3-sonnet-20240229",
        "claude-3-5-sonnet-20240620",
        "claude-3-5-sonnet-20241022",
        "c-3-5-sonnet-20241022",
        "gpt-4-turbo",
        "qwen-max",
        "glm-4"
        ],  
        baseline_models=["moonshot-v1-32k",
        "Doubao-pro-128k",
        "claude-3-5-sonnet-20241022"
#        "gpt-4-turbo",
#        "glm-4"],
        ],
        api_key_env="SMALLAI_API_KEY",
        base_url="https://ai98.vip/v1",
        model_class="ChatOpenAI"  # ä½¿ç”¨ OpenAI åŸºç±»
    ),
    "GoogleAPI": ModelVendorConfig(
        name="GoogleAPI",
        models=["gemini-1.5-flash","gemini-1.5-pro","gemini-2.0-flash-exp"],
        baseline_models=["gemini-1.5-flash"],
        api_key_env="GOOGLE_API_KEY",
        base_url=None,
        model_class="ChatGoogleGenerativeAI"
    ),
    "Ollama": ModelVendorConfig(
        name="Ollama",
        models=["qwen2.5-coder:7b", "llama2", "mistral", "mixtral", "codellama", "qwen", "yi"],
        baseline_models=["qwen2.5-coder:7b"],
        api_key_env=None,  # Ollama ä¸éœ€è¦ API key
        base_url="http://localhost:11434",  # é»˜è®¤çš„ Ollama åœ°å€
        model_class="Ollama"
    ),
    "LLMStudio": ModelVendorConfig(
        name="LLMStudio",
        models=["qwen2.5-coder-32b-instruct"],  # LLMStudio ä½œä¸ºæœ¬åœ°æœåŠ¡
        baseline_models=["qwen2.5-coder-32b-instruct"],
        api_key_env=None,
        base_url="http://localhost:1234/v1",  # é»˜è®¤çš„ LLMStudio åœ°å€
        model_class="LLMStudio"  # LLMStudio å…¼å®¹ OpenAI æ¥å£
    ),
    "Anthropic": ModelVendorConfig(
        name="Anthropic",
        models=["claude-3-opus", "claude-3-sonnet", "claude-2.1", "claude-2", "claude-instant"],
        baseline_models=["claude-3-opus", "claude-2.1"],
        api_key_env="ANTHROPIC_API_KEY",
        base_url="https://api.anthropic.com/v1",
        model_class="ChatAnthropic"
    ),
    "Zhipu": ModelVendorConfig(
        name="Zhipu",
        models=["chatglm_turbo", "chatglm_pro", "chatglm_std", "chatglm_lite", "glm-4", "glm-4v"],
        baseline_models=["glm-4"],
        api_key_env="ZHIPU_API_KEY",
        base_url="https://open.bigmodel.cn/api/paas/v3/model-api",
        model_class="ChatOpenAI"  # ä½¿ç”¨ OpenAI åŸºç±»
    ),
    "Baidu": ModelVendorConfig(
        name="Baidu",
        models=["ERNIE-Bot-4", "ERNIE-Bot", "ERNIE-Bot-turbo", "ERNIE-Bot-8k"],
        baseline_models=["ERNIE-Bot-4"],
        api_key_env="BAIDU_API_KEY",
        base_url="https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat",
        model_class="ChatOpenAI"  # ä½¿ç”¨ OpenAI åŸºç±»
    )
}

def get_model_configs():
    """è·å–æ¨¡å‹é…ç½®å¹¶éªŒè¯APIå¯†é’¥"""
    available_vendors = {}
    
    for vendor_name, config in MODEL_VENDORS.items():
        # å¦‚æœä¸éœ€è¦APIå¯†é’¥ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰æˆ–è€…æœ‰APIå¯†é’¥
        if config.api_key_env is None:
            available_vendors[vendor_name] = config
        else:
            api_key = os.getenv(config.api_key_env)
            if api_key:
                available_vendors[vendor_name] = config
    
    return available_vendors

class PromptTestRunner:
    def __init__(self):
        load_dotenv()
        
        # å®šä¹‰æç¤ºè¯ç›®å½•
        self.prompt_dir = "prompt_engineering/bot194/01"
        
        # å®šä¹‰æ—¥å¿—ç›®å½•å’Œæ–‡ä»¶
        self.log_dir = Path(__file__).parent / "test_logs"
        self.log_dir.mkdir(exist_ok=True)
        self.csv_log_file = self.log_dir / "test_results.csv"
        self.detail_log_dir = self.log_dir / "details"
        self.detail_log_dir.mkdir(exist_ok=True)
        
        # å®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„
        self.config_file = Path(__file__).parent / "config.json"
        
        # å¦‚æœCSVæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºå¹¶å†™å…¥è¡¨å¤´
        if not self.csv_log_file.exists():
            with open(self.csv_log_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow([
                    'æµ‹è¯•æ—¶é—´',
                    'æç¤ºè¯ç³»ç»Ÿ',
                    'æ¨¡å‹',
                    'æµ‹è¯•ç”¨ä¾‹',
                    'æ‰§è¡Œæ—¶é—´(ç§’)',
                    'æµ‹è¯•ç»“æœ',
                    'é”™è¯¯ä¿¡æ¯',
                    'è¯¦ç»†æ—¥å¿—æ–‡ä»¶'
                ])
        
        # å®šä¹‰æç¤ºè¯é…ç½®æ˜ å°„
        self.prompt_configs = {
            "å»ºé€ ç³»ç»Ÿ": {
                "prompt": "bot_skill_build_prompt_02.md",
                "test_cases": "bot_skill_build_test_cases.md"
            },
            "èµ„æºç®¡ç†": {
                "prompt": "resource_manager_prompt_02.md",
                "test_cases": "resource_manager_test_cases.md"
            },
            "æ•°ç»„å®šä¹‰": {
                "prompt": "array_definition_prompt.md",
                "test_cases": "array_definition_test_cases.md"
            },
        }
    
    def load_prompt(self, prompt_name: str):
        """åŠ è½½é€‰å®šçš„æç¤ºè¯"""
        config = self.prompt_configs[prompt_name]
        self.prompt_filename = config["prompt"]
        self.test_cases_filename = config["test_cases"]
        
        # ä»æ–‡ä»¶åŠ è½½ç³»ç»Ÿæç¤ºè¯
        prompt_file = Path(__file__).parent.parent / self.prompt_dir / self.prompt_filename
        with open(prompt_file, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # å¤„ç†æç¤ºè¯ä¸­çš„å˜é‡æ ‡è®°
        content = content.replace("{", "{{").replace("}", "}}")
        content = content.replace("{{{{", "{").replace("}}}}", "}")

        # ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
        self.system_prompt = content + """
æ³¨æ„ï¼š
1. ä½ å¿…é¡»ç›´æ¥è¿”å›JSONæ ¼å¼æ•°æ®ï¼Œä¸è¦åœ¨JSONå‰åæ·»åŠ ä»»ä½•å…¶ä»–æ–‡æœ¬ã€å¯¹è¯æˆ–è¯´æ˜
2. è¿”å›çš„JSONå¿…é¡»æ˜¯ä¸€ä¸ªå®Œæ•´ä¸”æœ‰æ•ˆçš„JSONå¯¹è±¡
3. æ‰€æœ‰å­—æ®µå€¼å¿…é¡»ç¬¦åˆå…¶é¢„æœŸçš„æ•°æ®ç±»å‹ï¼ˆä¾‹å¦‚ï¼šæ•°å­—ã€å­—ç¬¦ä¸²ã€å¸ƒå°”å€¼ã€å¯¹è±¡ç­‰ï¼‰
4. ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„å­—æ®µéƒ½å­˜åœ¨äºè¾“å‡ºä¸­
5. ä¸è¦åœ¨JSONä¸­æ·»åŠ æ³¨é‡Š
6. è¾“å‡ºJSONçš„é”®å€¼ç»Ÿä¸€ä½¿ç”¨å°å†™å­—æ¯
"""
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", self.system_prompt)
        ])
        return len(self.system_prompt)

    def load_test_cases(self, test_file_path: str) -> List[TestCase]:
        """ä»Markdownæ–‡ä»¶åŠ è½½æµ‹è¯•ç”¨ä¾‹"""
        test_cases = []
        
        with open(test_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        def extract_json_content(text: str, marker: str) -> str:
            start_marker = f"##### {marker}\n```json"
            end_marker = "```"
            start = text.find(start_marker)
            if start == -1:
                return ""
            start = start + len(start_marker)
            end = text.find(end_marker, start)
            if end == -1:
                return ""
            json_text = text[start:end].strip()
            return json_text
        
        test_sections = content.split('#### æµ‹è¯•ç”¨ä¾‹')
        loaded_cases = []
        errors = []
        
        for section in test_sections[1:]:
            try:
                name = section.split('\n')[0].strip()
                input_text = extract_json_content(section, "input.json")
                output_text = extract_json_content(section, "output.json")
                
                if not input_text or not output_text:
                    errors.append(f"æµ‹è¯•ç”¨ä¾‹ {name} ç¼ºå°‘è¾“å…¥æˆ–è¾“å‡ºJSON")
                    continue
                
                try:
                    input_json = json.loads(input_text)
                    output_json = json.loads(output_text)
                    
                    test_cases.append(TestCase(
                        name=name,
                        input_data=input_json,
                        expected_output=output_json
                    ))
                    loaded_cases.append(name)
                except json.JSONDecodeError as je:
                    errors.append(f"JSONè§£æé”™è¯¯ - æµ‹è¯•ç”¨ä¾‹ {name}: {str(je)}")
                    continue
                    
            except Exception as e:
                errors.append(f"è§£æé”™è¯¯ - æµ‹è¯•ç”¨ä¾‹ {name if 'name' in locals() else 'unknown'}: {str(e)}")
                continue
        
        return test_cases, loaded_cases, errors

    def get_chat_model(self, model_name: str, vendor_config: ModelVendorConfig):
        """æ ¹æ®æ¨¡å‹å•†é…ç½®è·å–å¯¹åº”çš„èŠå¤©æ¨¡å‹å®ä¾‹"""
        temperature = st.session_state.temperature

        if vendor_config.model_class == "ChatAnthropic":
            return ChatAnthropic(
                model=model_name,
                anthropic_api_key=os.getenv(vendor_config.api_key_env),
                temperature=temperature,
                streaming=True
            )
        elif vendor_config.model_class == "Ollama":
            return ChatOllama(
                model=model_name,
                base_url=vendor_config.base_url,
                temperature=temperature,
                streaming=True
            )
        elif vendor_config.model_class == "ChatGoogleGenerativeAI":
            return ChatGoogleGenerativeAI(
                model=model_name,
               api_key=os.getenv(vendor_config.api_key_env),
                temperature=temperature
                #,convert_system_message_to_human=True
            )
        elif vendor_config.model_class == "LLMStudio":  # é»˜è®¤ä½¿ç”¨ ChatOpenAIï¼ˆåŒ…æ‹¬ LLMStudioï¼Œå› ä¸ºå®ƒå…¼å®¹ OpenAI æ¥å£ï¼‰
            return ChatOpenAI(
                model=model_name,
                temperature=temperature,
                base_url=vendor_config.base_url
                #api_key=os.getenv(vendor_config.api_key_env),
                #streaming=True
            )
        else:  # é»˜è®¤ä½¿ç”¨ ChatOpenAIï¼ˆåŒ…æ‹¬ LLMStudioï¼Œå› ä¸ºå®ƒå…¼å®¹ OpenAI æ¥å£ï¼‰
            return ChatOpenAI(
                model=model_name,
                temperature=temperature,
                base_url=vendor_config.base_url,
                api_key=os.getenv(vendor_config.api_key_env),
                streaming=True
            )

    def _validate_output_format(self, output: Dict[str, Any]):
        """éªŒè¯è¾“å‡ºæ ¼å¼æ˜¯å¦ç¬¦åˆè§„èŒƒ"""
        if not isinstance(output, dict):
            raise ValueError("Output must be a dictionary")
        
        required_fields = ["updated_context", "process", "botstatus", "message", "dialogue"]
        for field in required_fields:
            if field not in output:
                raise ValueError(f"Missing required field: {field}")

    def run_test(self, test_case: Dict[str, Any], expected_output: Dict[str, Any], model: str) -> tuple[bool, Dict[str, Any], float, str]:
        """è¿è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹å¹¶è¿”å›ç»“æœã€å®é™…è¾“å‡ºã€æ‰§è¡Œæ—¶é—´å’Œé”™è¯¯ä¿¡æ¯"""
        start_time = time.time()
        error_msg = ""
        actual_output = {}
        
        try:
            input_json = json.dumps(test_case, ensure_ascii=False, indent=2)
            
            system_content = self.system_prompt.format(
                input=test_case.get("input", ""),
                context=json.dumps(test_case.get("context", {}), ensure_ascii=False)
            )
            
            try:
                # è·å–å½“å‰é€‰ä¸­çš„æ¨¡å‹å•†é…ç½®
                vendor_config = st.session_state.selected_vendor
                
                # æ ¹æ®æ¨¡å‹å•†é…ç½®è·å–èŠå¤©æ¨¡å‹å®ä¾‹
                chat = self.get_chat_model(model, vendor_config)
                
                messages = [
                    SystemMessage(content=system_content),
                    HumanMessage(content=input_json)
                ]
                
                result = chat.invoke(messages)
                #print(result.content)
                #st.sidebar.write(result.content)

                try:
                    content = result.content
                    json_start = content.find('{')
                    json_end = content.rfind('}')
                    if json_start != -1 and json_end != -1:
                        content = content[json_start:json_end + 1]
                    
                    actual_output = json.loads(content)
                    self._validate_output_format(actual_output)
                    
                    is_match, error_details = self._compare_outputs(actual_output, expected_output)
                    if is_match:
                        return True, actual_output, time.time() - start_time, ""
                    else:
                        error_msg = "è¾“å‡ºä¸é¢„æœŸä¸åŒ¹é…ï¼š\n" + "\n".join(error_details)
                        return False, actual_output, time.time() - start_time, error_msg
                        
                except json.JSONDecodeError:
                    error_msg = "AIå“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼"
                    return False, {}, time.time() - start_time, error_msg
                    
            except Exception as e:
                error_msg = f"APIè°ƒç”¨é”™è¯¯: {str(e)}"
                return False, {}, time.time() - start_time, error_msg
                
        except Exception as e:
            error_msg = f"æµ‹è¯•æ‰§è¡Œå‡ºé”™: {str(e)}"
            return False, {}, time.time() - start_time, error_msg

    def _compare_outputs(self, actual: Dict[str, Any], expected: Dict[str, Any]) -> tuple[bool, list]:
        """æ¯”è¾ƒå®é™…è¾“å‡ºå’Œé¢„æœŸè¾“å‡ºï¼Œè¿”å›æ˜¯å¦åŒ¹é…å’Œä¸åŒ¹é…çš„è¯¦ç»†ä¿¡æ¯"""
        def compare_dicts(actual_dict: Dict[str, Any], expected_dict: Dict[str, Any], path: str = "") -> tuple[bool, list]:
            errors = []
            for key, expected_value in expected_dict.items():
                if key not in actual_dict:
                    errors.append(f"ç¼ºå°‘å­—æ®µ {path}{key}")
                    continue
                    
                actual_value = actual_dict[key]
                
                if isinstance(expected_value, dict):
                    if not isinstance(actual_value, dict):
                        errors.append(f"å­—æ®µç±»å‹ä¸åŒ¹é… {path}{key}ï¼šæœŸæœ› dictï¼Œå®é™… {type(actual_value).__name__}")
                        continue
                    sub_result, sub_errors = compare_dicts(actual_value, expected_value, f"{path}{key}.")
                    errors.extend(sub_errors)
                elif isinstance(expected_value, (int, float)):
                    if not isinstance(actual_value, (int, float)):
                        errors.append(f"æ•°å€¼ç±»å‹ä¸åŒ¹é… {path}{key}ï¼šæœŸæœ› numberï¼Œå®é™… {type(actual_value).__name__}")
                        continue
                    if abs(actual_value - expected_value) > 0.01:
                        errors.append(f"æ•°å€¼ä¸åŒ¹é… {path}{key}ï¼šæœŸæœ› {expected_value}ï¼Œå®é™… {actual_value}")
                elif isinstance(expected_value, bool):
                    if not isinstance(actual_value, bool):
                        errors.append(f"å¸ƒå°”ç±»å‹ä¸åŒ¹é… {path}{key}ï¼šæœŸæœ› boolï¼Œå®é™… {type(actual_value).__name__}")
                        continue
                    if actual_value != expected_value:
                        errors.append(f"å¸ƒå°”å€¼ä¸åŒ¹é… {path}{key}ï¼šæœŸæœ› {expected_value}ï¼Œå®é™… {actual_value}")
                elif isinstance(expected_value, str):
                    if not isinstance(actual_value, str):
                        errors.append(f"å­—æ®µç±»å‹ä¸åŒ¹é… {path}{key}ï¼šæœŸæœ› stringï¼Œå®é™… {type(actual_value).__name__}")
                        continue
                    # å­—ç¬¦ä¸²åªæ£€æŸ¥ç±»å‹ï¼Œä¸æ¯”è¾ƒå†…å®¹
                elif isinstance(expected_value, list):
                    if not isinstance(actual_value, list):
                        errors.append(f"åˆ—è¡¨ç±»å‹ä¸åŒ¹é… {path}{key}ï¼šæœŸæœ› listï¼Œå®é™… {type(actual_value).__name__}")
                        continue
                    if len(actual_value) != len(expected_value):
                        errors.append(f"åˆ—è¡¨é•¿åº¦ä¸åŒ¹é… {path}{key}ï¼šæœŸæœ› {len(expected_value)}ï¼Œå®é™… {len(actual_value)}")
                    # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ åˆ—è¡¨å…ƒç´ çš„è¯¦ç»†æ¯”è¾ƒ
                    
            return len(errors) == 0, errors
            
        is_match, error_details = compare_dicts(actual, expected)
        return is_match, error_details

    def get_chat_model(self, model_name: str, vendor_config: ModelVendorConfig):
        """æ ¹æ®æ¨¡å‹å•†é…ç½®è·å–å¯¹åº”çš„èŠå¤©æ¨¡å‹å®ä¾‹"""
        temperature = st.session_state.temperature

        if vendor_config.model_class == "ChatAnthropic":
            return ChatAnthropic(
                model=model_name,
                anthropic_api_key=os.getenv(vendor_config.api_key_env),
                temperature=temperature,
                streaming=True
            )
        elif vendor_config.model_class == "Ollama":
            return ChatOllama(
                model=model_name,
                base_url=vendor_config.base_url,
                temperature=temperature,
                streaming=True
            )
        elif vendor_config.model_class == "ChatGoogleGenerativeAI":
            return ChatGoogleGenerativeAI(
                model=model_name,
                api_key=os.getenv(vendor_config.api_key_env),
                temperature=temperature,
                verbose=True
            )
        elif vendor_config.model_class == "LLMStudio":  # é»˜è®¤ä½¿ç”¨ ChatOpenAIï¼ˆåŒ…æ‹¬ LLMStudioï¼Œå› ä¸ºå®ƒå…¼å®¹ OpenAI æ¥å£ï¼‰
            return ChatOpenAI(
                model=model_name,
                temperature=temperature,
                base_url=vendor_config.base_url
                #api_key=os.getenv(vendor_config.api_key_env),
                #streaming=True
            )
        else:  # é»˜è®¤ä½¿ç”¨ ChatOpenAIï¼ˆåŒ…æ‹¬ LLMStudioï¼Œå› ä¸ºå®ƒå…¼å®¹ OpenAI æ¥å£ï¼‰
            return ChatOpenAI(
                model=model_name,
                temperature=temperature,
                base_url=vendor_config.base_url,
                api_key=os.getenv(vendor_config.api_key_env),
                streaming=True,
                verbose=True
            )

    def save_test_results(self, prompt_system: str, model: str, case_name: str, 
                         result: Dict[str, Any], test_time: str = None):
        """ä¿å­˜æµ‹è¯•ç»“æœåˆ°CSVå’Œè¯¦ç»†æ—¥å¿—æ–‡ä»¶"""
        if test_time is None:
            test_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
        # åˆ›å»ºè¯¦ç»†æ—¥å¿—æ–‡ä»¶å
        detail_file_name = f"{test_time.replace(':', '-')}_{model}_{case_name}.json"
        detail_file_path = self.detail_log_dir / detail_file_name
        
        # ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSONæ–‡ä»¶
        with open(detail_file_path, 'w', encoding='utf-8') as f:
            json.dump({
                "test_time": test_time,
                "prompt_system": prompt_system,
                "model": model,
                "case_name": case_name,
                "input_data": result["input_data"],
                "expected_output": result["expected_output"],
                "actual_output": result["actual_output"],
                "passed": result["passed"],
                "execution_time": result["execution_time"],
                "error": result["error"]
            }, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶
        with open(self.csv_log_file, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                test_time,
                prompt_system,
                model,
                case_name,
                f"{result['execution_time']:.2f}",
                "é€šè¿‡" if result["passed"] else "å¤±è´¥",
                result["error"] or "",
                detail_file_name
            ])

def load_config():
    """åŠ è½½æŒä¹…åŒ–çš„é…ç½®"""
    config_file = Path(__file__).parent / "config.json"
    if config_file.exists():
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                st.session_state.update(config)
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")

def save_config():
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
    config_file = Path(__file__).parent / "config.json"
    config = {
        'temperature': st.session_state.temperature,
        'selected_vendor_name': st.session_state.get('previous_vendor'),
        'selected_models': st.session_state.get('selected_models', []),
        'selected_prompt_project': st.session_state.get('prompt_project_selector')
    }
    try:
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=4)
    except Exception as e:
        logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")

def main():
    st.set_page_config(
        page_title="Prompt Test Runner",
        page_icon="ğŸ§ª",
        layout="wide"
    )
    
    st.title("ğŸ§ª Prompt Test Runner")
    
    # åˆå§‹åŒ–æµ‹è¯•è¿è¡Œå™¨å¹¶åŠ è½½é…ç½®
    if 'runner' not in st.session_state:
        st.session_state.runner = PromptTestRunner()
        st.session_state.test_cases = []
        st.session_state.loaded_cases = []
        st.session_state.errors = []
        st.session_state.results = {}
        
        # åŠ è½½æŒä¹…åŒ–çš„é…ç½®
        config_file = Path(__file__).parent / "config.json"
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    # è®¾ç½®é»˜è®¤å€¼
                    st.session_state.temperature = config.get('temperature', 0.7)
                    st.session_state.previous_vendor = config.get('selected_vendor_name')
                    st.session_state.selected_models = config.get('selected_models', [])
                    st.session_state.prompt_project_selector = config.get('selected_prompt_project')
            except Exception as e:
                logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
                # è®¾ç½®é»˜è®¤å€¼
                st.session_state.temperature = 0.7
                st.session_state.previous_vendor = None
                st.session_state.selected_models = []
                st.session_state.prompt_project_selector = None
        else:
            # è®¾ç½®é»˜è®¤å€¼
            st.session_state.temperature = 0.7
            st.session_state.previous_vendor = None
            st.session_state.selected_models = []
            st.session_state.prompt_project_selector = None
        
    # è·å–å¯ç”¨çš„æ¨¡å‹å•†é…ç½®
    available_vendors = get_model_configs()
    
    if not available_vendors:
        st.error("æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æ¨¡å‹é…ç½®ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥è®¾ç½®")
        return
        
    # å¯é€‰æ¨¡å‹åˆ—è¡¨
    models = []
    for vendor in available_vendors.values():
        models.extend(vendor.models)
    
    # baseline æ¨¡å‹åˆ—è¡¨
    baseline_models = []
    for vendor in available_vendors.values():
        baseline_models.extend(vendor.baseline_models)
    
    # åˆ›å»ºä¾§è¾¹æ 
    with st.sidebar:
        st.markdown("### é…ç½®")
        
        # æ·»åŠ  temperature è°ƒæ•´æ»‘åŠ¨æ¡
        temperature = st.slider(
            "Temperature",
            min_value=0.0,
            max_value=2.0,
            value=st.session_state.temperature,
            step=0.1,
            help="è°ƒæ•´æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§ï¼š0è¡¨ç¤ºè¾“å‡ºæœ€ç¡®å®šï¼Œ2è¡¨ç¤ºè¾“å‡ºæœ€éšæœº"
        )
        
        # æ›´æ–°temperatureå€¼
        if temperature != st.session_state.temperature:
            st.session_state.temperature = temperature
        
        # æç¤ºè¯é¡¹ç›®é€‰æ‹©
        if 'prompt_project_selector' not in st.session_state:
            st.session_state.prompt_project_selector = list(st.session_state.runner.prompt_configs.keys())[0]
            
        prompt_projects = list(st.session_state.runner.prompt_configs.keys())
        selected_prompt_project = st.selectbox(
            "é€‰æ‹©æç¤ºè¯é¡¹ç›®",
            options=prompt_projects,
            index=prompt_projects.index(st.session_state.prompt_project_selector)
        )
        
        # æ›´æ–° session state
        st.session_state.prompt_project_selector = selected_prompt_project
        
        # å½“æç¤ºè¯é¡¹ç›®æ”¹å˜æ—¶ï¼Œæ¸…ç©ºä¹‹å‰çš„æµ‹è¯•ç”¨ä¾‹é€‰æ‹©
        if 'last_selected_project' not in st.session_state:
            st.session_state.last_selected_project = selected_prompt_project
        elif st.session_state.last_selected_project != selected_prompt_project:
            st.session_state.last_selected_project = selected_prompt_project
            if 'selected_test_cases' in st.session_state:
                st.session_state.selected_test_cases = []
            if 'test_cases' in st.session_state:
                st.session_state.test_cases = None
            if 'all_selected' in st.session_state:
                st.session_state.all_selected = False
        
        st.markdown("---")
        
        # æ¨¡å‹é€‰æ‹©
        st.markdown("### é€‰æ‹©æ¨¡å‹")
        vendor_names = list(available_vendors.keys())
        
        # ä½¿ç”¨ä¿å­˜çš„vendor_nameä½œä¸ºé»˜è®¤å€¼
        default_vendor_index = 0
        if st.session_state.previous_vendor in vendor_names:
            default_vendor_index = vendor_names.index(st.session_state.previous_vendor)
        
        selected_vendor_name = st.selectbox(
            "é€‰æ‹©æ¨¡å‹å•†",
            options=vendor_names,
            index=default_vendor_index
        )
        
        # è·å–é€‰ä¸­çš„æ¨¡å‹å•†é…ç½®
        selected_vendor = available_vendors[selected_vendor_name]
        st.session_state.selected_vendor = selected_vendor
        
        # å½“æ¨¡å‹å•†æ”¹å˜æ—¶ï¼Œé‡ç½®é€‰ä¸­çš„æ¨¡å‹åˆ—è¡¨
        if st.session_state.previous_vendor != selected_vendor_name:
            # å¦‚æœæœ‰ä¿å­˜çš„æ¨¡å‹åˆ—è¡¨ä¸”å±äºå½“å‰vendorï¼Œä½¿ç”¨ä¿å­˜çš„åˆ—è¡¨
            if (len(st.session_state.selected_models) > 0 and 
                all(model in selected_vendor.models for model in st.session_state.selected_models)):
                pass
            else:
                st.session_state.selected_models = [selected_vendor.models[0]]
            st.session_state.previous_vendor = selected_vendor_name
        
        # é€‰æ‹©åŸºçº¿æ¨¡å‹æŒ‰é’®
        if st.button("é€‰æ‹©åŸºçº¿æ¨¡å‹"):
            st.session_state.selected_models = selected_vendor.baseline_models
        
        # å¤šé€‰æ¨¡å‹
        selected_models = st.multiselect(
            "é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹",
            options=selected_vendor.models,
            default=st.session_state.selected_models
        )
        
        # æ›´æ–°é€‰æ‹©çš„æ¨¡å‹
        if selected_models != st.session_state.selected_models:
            st.session_state.selected_models = selected_models
        
    # ä¸»ç•Œé¢
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # åŠ è½½æç¤ºè¯å’Œæµ‹è¯•ç”¨ä¾‹æŒ‰é’®
        if st.button("åŠ è½½æç¤ºè¯å’Œæµ‹è¯•ç”¨ä¾‹", key="load_button"):
            with st.spinner("æ­£åœ¨åŠ è½½..."):
                # ä¿å­˜å½“å‰é…ç½®
                save_config()
                
                # åŠ è½½æç¤ºè¯
                prompt_length = st.session_state.runner.load_prompt(selected_prompt_project)
                st.success(f"æç¤ºè¯åŠ è½½å®Œæˆï¼Œé•¿åº¦ï¼š{prompt_length}")
                
                # åŠ è½½æµ‹è¯•ç”¨ä¾‹
                test_file = Path(__file__).parent.parent / st.session_state.runner.prompt_dir / st.session_state.runner.test_cases_filename
                st.session_state.test_cases, st.session_state.loaded_cases, st.session_state.errors = st.session_state.runner.load_test_cases(str(test_file))
                
                if st.session_state.test_cases:
                    st.success(f"æˆåŠŸåŠ è½½ {len(st.session_state.test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
                if st.session_state.errors:
                    st.error("\n".join(st.session_state.errors))
        
        # æµ‹è¯•ç”¨ä¾‹é€‰æ‹©éƒ¨åˆ†
        if hasattr(st.session_state, 'test_cases') and st.session_state.test_cases:
            st.subheader("é€‰æ‹©æµ‹è¯•ç”¨ä¾‹")
            # å…¨é€‰/å–æ¶ˆå…¨é€‰æŒ‰é’®
            if st.button("å…¨é€‰" if not st.session_state.get('all_selected', False) else "å–æ¶ˆå…¨é€‰"):
                st.session_state.all_selected = not st.session_state.get('all_selected', False)
                if st.session_state.all_selected:
                    st.session_state.selected_test_cases = [case.name for case in st.session_state.test_cases]
                else:
                    st.session_state.selected_test_cases = []
                st.rerun()
            
            # æµ‹è¯•ç”¨ä¾‹å¤šé€‰
            selected_cases = st.multiselect(
                "é€‰æ‹©è¦è¿è¡Œçš„æµ‹è¯•ç”¨ä¾‹",
                options=[case.name for case in st.session_state.test_cases],
                default=st.session_state.get('selected_test_cases', [])
            )
            # æ›´æ–°é€‰ä¸­çš„æµ‹è¯•ç”¨ä¾‹
            st.session_state.selected_test_cases = selected_cases
    
    with col2:
        if hasattr(st.session_state, 'test_cases') and st.session_state.test_cases:
            st.subheader("å·²é€‰æ‹©çš„æ¨¡å‹")
            model_list = ", ".join([f"`{model}`" for model in st.session_state.selected_models])
            st.markdown(f"å·²é€‰æ‹©çš„æ¨¡å‹: {model_list}")
            
            # è¿è¡Œæµ‹è¯•æŒ‰é’®
            if st.button("è¿è¡Œæµ‹è¯•", key="run_button", disabled=not st.session_state.selected_test_cases):
                # ä¿å­˜å½“å‰é…ç½®
                save_config()
                
                # å¯¹æ¯ä¸ªé€‰ä¸­çš„æ¨¡å‹è¿è¡Œæµ‹è¯•
                test_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                for model in st.session_state.selected_models:
                    st.subheader(f"æ¨¡å‹: {model}")
                    model_results = {}
                    
                    for case_name in st.session_state.selected_test_cases:
                        test_case = next(case for case in st.session_state.test_cases if case.name == case_name)
                        with st.spinner(f"æ­£åœ¨è¿è¡Œæµ‹è¯•ç”¨ä¾‹: {case_name}"):
                            passed, actual_output, execution_time, error = st.session_state.runner.run_test(
                                test_case.input_data,
                                test_case.expected_output,
                                model
                            )
                            
                            result = {
                                "passed": passed,
                                "execution_time": execution_time,
                                "error": error,
                                "actual_output": actual_output,
                                "expected_output": test_case.expected_output,
                                "input_data": test_case.input_data
                            }
                            
                            model_results[case_name] = result
                            
                            # ä¿å­˜æµ‹è¯•ç»“æœ
                            st.session_state.runner.save_test_results(
                                selected_prompt_project,
                                model,
                                case_name,
                                result,
                                test_time
                            )
                    
                    st.session_state.results[model] = model_results
        
    # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
    if st.session_state.results:
        st.subheader("æµ‹è¯•ç»“æœ")
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹æ˜¾ç¤ºç»“æœ
        for model, model_results in st.session_state.results.items():
            st.markdown(f"### æ¨¡å‹: {model}")
            
            # è®¡ç®—ç»Ÿè®¡æ•°æ®
            total = len(model_results)
            passed = sum(1 for r in model_results.values() if r["passed"])
            failed = total - passed
            pass_rate = (passed/total)*100 if total > 0 else 0
            total_time = sum(r["execution_time"] for r in model_results.values())
            avg_time = total_time / total if total > 0 else 0
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            cols = st.columns(6)
            cols[0].metric("æ€»ç”¨ä¾‹æ•°", total)
            cols[1].metric("é€šè¿‡", passed)
            cols[2].metric("å¤±è´¥", failed)
            cols[3].metric("é€šè¿‡ç‡", f"{pass_rate:.1f}%")
            cols[4].metric("æ€»è€—æ—¶", f"{total_time:.2f}ç§’")
            cols[5].metric("å¹³å‡è€—æ—¶", f"{avg_time:.2f}ç§’")
            
            # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
            for case_name, result in model_results.items():
                with st.expander(f"{'âœ…' if result['passed'] else 'âŒ'} {case_name} ({result['execution_time']:.2f}ç§’)"):
                    if result["error"]:
                        st.error(result["error"])
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.subheader("è¾“å…¥")
                        st.json(result["input_data"])
                    
                    with col2:
                        st.subheader("æœŸæœ›è¾“å‡º")
                        st.json(result["expected_output"])
                    
                    with col3:
                        st.subheader("å®é™…è¾“å‡º")
                        if result["actual_output"]:
                            st.json(result["actual_output"])
                        else:
                            st.error("æ— è¾“å‡º")

    # æ·»åŠ æŸ¥çœ‹å†å²è®°å½•éƒ¨åˆ†
    st.divider()  # æ·»åŠ åˆ†éš”çº¿
    st.subheader("å†å²è®°å½•æŸ¥çœ‹")
    
    if os.path.exists(st.session_state.runner.csv_log_file):
        # ä¸‹è½½æŒ‰é’®å’Œæœ€è¿‘è®°å½•æ˜¾ç¤º
        with open(st.session_state.runner.csv_log_file, 'r', encoding='utf-8') as f:
            csv_content = f.read()
        st.download_button(
            "ä¸‹è½½CSVæµ‹è¯•è®°å½•",
            csv_content,
            "test_results.csv",
            "text/csv",
            key='download_csv'
        )
        
        # æ˜¾ç¤ºæœ€è¿‘çš„æµ‹è¯•è®°å½•
        st.subheader("æœ€è¿‘çš„æµ‹è¯•è®°å½•")
        df = pd.read_csv(st.session_state.runner.csv_log_file)
        st.dataframe(df.tail(10))
        
        # ä¸‰æ å¸ƒå±€æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
        st.subheader("è¯¦ç»†æ—¥å¿—æŸ¥çœ‹")
        log_files = list(st.session_state.runner.detail_log_dir.glob("*.json"))
        if log_files:
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰é¢
            log_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
            
            # åˆ›å»ºä¸€ä¸ªæ›´å‹å¥½çš„æ˜¾ç¤ºæ ¼å¼
            log_options = {}
            for f in log_files:
                # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                mtime = datetime.datetime.fromtimestamp(os.path.getmtime(f))
                # åˆ›å»ºæ˜¾ç¤ºåç§°ï¼šæ—¶é—´ - æ¨¡å‹ - æµ‹è¯•ç”¨ä¾‹
                display_name = f"{mtime.strftime('%Y-%m-%d %H:%M:%S')} - {f.stem}"
                log_options[display_name] = f
            
            # ä¸Šéƒ¨åˆ†ï¼šä¸¤æ å¸ƒå±€æ˜¾ç¤ºæ—¥å¿—åˆ—è¡¨å’ŒåŸºæœ¬ä¿¡æ¯
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### æ—¥å¿—åˆ—è¡¨")
                selected_log_display = st.selectbox(
                    "é€‰æ‹©è¦æŸ¥çœ‹çš„æ—¥å¿—",
                    options=list(log_options.keys()),
                    key='log_selector_new'
                )
            
            if selected_log_display:
                selected_log_file = log_options[selected_log_display]
                with open(selected_log_file, 'r', encoding='utf-8') as f:
                    log_data = json.load(f)
                    
                with col2:
                    st.markdown("#### æµ‹è¯•ä¿¡æ¯")
                    st.write(f"**æµ‹è¯•æ—¶é—´:** {log_data['test_time']}")
                    st.write(f"**æç¤ºè¯ç³»ç»Ÿ:** {log_data['prompt_system']}")
                    st.write(f"**æ¨¡å‹:** {log_data['model']}")
                    st.write(f"**æµ‹è¯•ç”¨ä¾‹:** {log_data['case_name']}")
                    st.write(f"**æ‰§è¡Œæ—¶é—´:** {log_data['execution_time']:.2f}ç§’")
                    st.write(f"**æµ‹è¯•ç»“æœ:** {'âœ… é€šè¿‡' if log_data['passed'] else 'âŒ å¤±è´¥'}")
                    if log_data['error']:
                        st.error(f"é”™è¯¯ä¿¡æ¯:\n{log_data['error']}")
                
                # ä¸‹éƒ¨åˆ†ï¼šä¸‰æ å¸ƒå±€æ˜¾ç¤ºæ•°æ®
                st.divider()
                data_col1, data_col2, data_col3 = st.columns(3)
                
                with data_col1:
                    st.markdown("#### è¾“å…¥æ•°æ®")
                    st.json(log_data['input_data'])
                
                with data_col2:
                    st.markdown("#### æœŸæœ›è¾“å‡º")
                    st.json(log_data['expected_output'])
                    
                with data_col3:
                    st.markdown("#### å®é™…è¾“å‡º")
                    st.json(log_data['actual_output'])

if __name__ == "__main__":
    main()
